<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="description" content="TensorFlow Object Detection API使用小结 - Shaun&#39;s Space"><meta name="keywords" content="cv,tensorflow"><meta property="og:type" content="article"><meta property="og:site_name" content="Shaun&#39;s Space"><title>TensorFlow Object Detection API使用小结 - Shaun&#39;s Space</title><link rel="icon" href="/img/favicon.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous"><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/fork-awesome/1.1.5/css/fork-awesome.min.css" integrity="sha256-P64qV9gULPHiZTdrS1nM59toStkgjM0dsf5mK/UwBV4=" crossorigin="anonymous"><script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><script src="//cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha256-ZvOgfh+ptkpoa2Y4HkRY28ir89u/+VRyDE7sB7hEEcI=" crossorigin="anonymous"></script><script src="//cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script><script src="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js" integrity="sha256-EPrkNjGEmCWyazb3A/Epj+W7Qm2pB9vnfXw+X6LImPM=" crossorigin="anonymous"></script><script src="//cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><link rel="stylesheet" href="/css/style.css"><style>body{cursor:url(/img/cursor/normal.cur),auto}#navbar-toggler--btn,.code-copy,.copy-path,a,button{cursor:url(/img/cursor/link.cur),auto}#site-bg{position:fixed;left:0;top:0;width:100%;height:100%;z-index:-1;background-image:url(/img/site-bg/bg-7.jpg);background-repeat:no-repeat;background-size:100% 100%;opacity:.2;transition:background-image 3s}</style><script>const bdshareURL="/plugins/baidushare/"</script><script async type="text/javascript" src="/js/live2d/autoload.js"></script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Shaun's Space" type="application/atom+xml">
</head><body><!--[if lt IE 9]>
        <link rel="stylesheet" href="/css/ie9.css">
        <div class="alert alert-danger topframe" role="alert">
            嘿，朋友！您的浏览器已<strong>过期</strong>，不建议继续食用。
            <a target="_blank" class="alert-link" href="http://browsehappy.com">这里</a> 有些新玩意儿，何不试试？
        </div>
    <![endif]--><header id="header"><nav id="navbar" class="navbar navbar-expand-md"><div class="container"><h1 id="site-title"><a href="/" class="navbar-brand"><img src="/img/favicon.png"> <span>Shaun&#39;s Space</span></a></h1><button id="navbar-toggler--btn" class="navbar-toggler" type="button" data-toggle="collapse" data-target="#collapsibleNavbar"><span><i class="fa fa-list-ul" aria-hidden="true"></i></span></button><div class="collapse navbar-collapse" id="collapsibleNavbar"><ul class="navbar-nav"><li class="nav-item"><a class="nav-link" href="/" title="首页" data-toggle="tooltip" data-placement="bottom"><i class="nav-icon fa fa-home"></i> 首页</a></li><li class="nav-item"><a class="nav-link" href="/archives" title="所有文章" data-toggle="tooltip" data-placement="bottom"><i class="nav-icon fa fa-archive"></i> 归档</a></li><li class="nav-item"><a class="nav-link" href="/categories" title="全部分类" data-toggle="tooltip" data-placement="bottom"><i class="nav-icon fa fa-folder"></i> 分类</a></li><li class="nav-item"><a class="nav-link" href="/tags" title="全部标签" data-toggle="tooltip" data-placement="bottom"><i class="nav-icon fa fa-tags"></i> 标签</a></li><li class="nav-item"><a class="nav-link" href="/about" title="关于本站" data-toggle="tooltip" data-placement="bottom"><i class="nav-icon fa fa-user"></i> 关于</a></li><li class="nav-item"><a class="nav-link" href="/guide" title="Treasure Guide" data-toggle="tooltip" data-placement="bottom"><i class="nav-icon fa fa-university"></i> 导航</a></li></ul></div></div></nav></header><div class="container"><div class="row"><aside id="left-col" class="col-md-1"></aside><main class="col-lg-8 col-sm-12"><article id="post-TensorFlow-Object-Detection-API使用小结" class="article div-border"><header class="article-header"><span class="article-date article-title--post"><i class="fa fa-calendar" aria-hidden="true"></i> <a href="/posts/82d3b275.html"><time datetime="2017-11-11T13:52:52.000Z">2017-11-11</time></a></span><section class="article-title article-title--post"><a href="/posts/82d3b275.html">TensorFlow Object Detection API使用小结</a></section><div class="article-label"><div class="article-category label"><i class="fa fa-book" aria-hidden="true"></i> <a class="color5 article-category-link" href="/categories/Image-Graphic/">Image&Graphic</a></div><div class="article-tag label"><i class="fa fa-bookmark" aria-hidden="true"></i> <a class="color5 article-tag-none-link" href="/tags/cv/" rel="tag">cv</a><a class="color5 article-tag-none-link" href="/tags/tensorflow/" rel="tag">tensorflow</a></div></div></header><section class="article-content"><p><font color="#FA8072">本文所用的 Python 版本为 python-3.6.2，TensorFlow 版本为tensorflow-1.4.0，编程语言为 python3，系统环境为 Windows 10。</font></p><h2 id="前言">前言</h2><p>　　很久没写过东西了，主要原因是最近研究生课程开始陆续结课，Shaun 也要忙于应付各种结课时的考试、论文、project 等一堆麻烦事。这不深度学习结课时需要做个 project，Shaun 也顺便将做这个 project 的过程记录下来。</p><span id="more"></span><h2 id="准备篇">准备篇</h2><p>　　该 project 主要利用 TensorFlow 中的 Object Detection API 进行训练和检测。在开始使用该 API 之前需要安装配置 Python 环境。</p><p>　　既然是 Python 首先需要 <a target="_blank" rel="noopener" href="https://www.python.org/downloads/">下载安装Python</a>，安装完之后，为了顺利使用 pip 需要配置环境变量，在 Windows 系统环境变量中 Path 末尾添加：</p><table><colgroup><col style="width:9%"><col style="width:90%"></colgroup><thead><tr class="header"><th style="text-align:center">变量名</th><th style="text-align:center">变量值</th></tr></thead><tbody><tr class="odd"><td style="text-align:center">Path</td><td style="text-align:center">;C:\Users\admin\AppData\Local\Programs\Python\Python36\; C:\Users\admin\AppData\Local\Programs\Python\Python36\Scripts\</td></tr></tbody></table><p>其中 <code>C:\Users\admin\AppData\Local\Programs\Python\Python36</code> 为 python-3.6.2 默认安装目录。</p><p>　　然后为了方便使用命令行工具，<a target="_blank" rel="noopener" href="https://www.git-scm.com/download/">下载安装git</a>，安装方式一路默认即可。</p><p>　　接下来利用 pip 安装 TensorFlow，鼠标右键桌面空白处，点击“<strong>Git Bash Here</strong>”，打开 bash 命令行，输入 <code>pip install tensorflow</code>，其中一些依赖关系可能需要手动解决，手动解决的办法就是用 pip install 相关依赖库，这是 CPU 版的 TensorFlow，若要使用 GPU，则需要安装 GPU 版的 TensorFlow，安装命令为：<code>pip install tensorflow-gpu</code>，以同样方式解决依赖关系。由于 Shaun 电脑没 N 卡，所以没安装 GPU 版的 TensorFlow，所以如果想使用 GPU 版的 TensorFlow 请另行尝试。</p><p>　　然后安装 TensorFlow Object Detection API 依赖库，在命令行中输入：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false" data-lang="BASH"><div class="code-copy"></div><figure class="highlight hljs bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip install pillow</span><br><span class="line">pip install lxml</span><br><span class="line">pip install jupyter</span><br><span class="line">pip install matplotlib </span><br></pre></td></tr></table></figure></div><p>　　因为 tensorflow 并没有默认自带 Object Detection API，所以该 API 需要自行下载，下载地址为：https://github.com/tensorflow/models ，下载之后解压，Shaun 解压目录为：<code>D:\ProgramFiles\PythonLibs\tensorflow</code>，解压完之后需要配置环境目录，在系统环境目录中添加：</p><table><colgroup><col style="width:20%"><col style="width:80%"></colgroup><thead><tr class="header"><th style="text-align:center">变量名</th><th style="text-align:center">变量值</th></tr></thead><tbody><tr class="odd"><td style="text-align:center">PYTHONPATH</td><td style="text-align:center">D:\ProgramFiles\PythonLibs\tensorflow\models; D:\ProgramFiles\PythonLibs\tensorflow\models\research; D:\ProgramFiles\PythonLibs\tensorflow\models\research\slim;</td></tr></tbody></table><p>　　下载配置 Object Detection API 完之后需要安装 Protoc，进入 <a target="_blank" rel="noopener" href="https://github.com/google/protobuf/releases">Protoc下载页</a>，下载 <a target="_blank" rel="noopener" href="https://github.com/google/protobuf/releases/download/v3.4.0/protoc-3.4.0-win32.zip"><strong>protoc-3.4.0-win32.zip</strong></a>，解压之后将 <strong>bin</strong> 文件夹内的 <strong>protoc.exe</strong> 拷贝到 <code>C:\windows\system32</code> 目录下（用于将 protoc.exe 所在的目录配置到环境变量当中）,当然也可以在系统环境变量 Path 中添加该 <strong>bin</strong> 文件夹路径。</p><p>　　最后在命令行中切换目录至：<code>D:\ProgramFiles\PythonLibs\tensorflow\models\research</code> 文件夹，即 object_detection 文件夹所在目录，在命令行中输入：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false" data-lang="BASH"><div class="code-copy"></div><figure class="highlight hljs bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></table></figure></div><p>编译 <code>object_detection/protos</code> 文件夹下的 proto 文件，生成对应的 python 文件。</p><p>　　至此，Windows 下 TensorFlow中 的 Object Detection API 的使用配置全部完成，至于 Ubuntu 下的配置可参考其<a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md">官方文档</a>。</p><p>　　至于如何验证，可以在命令行中切换目录至 <code>object_detection</code>，输入：<code>jupyter notebook</code>，稍等一会，浏览器将自动打开 <code>http://localhost:8888/tree</code> jupyter 界面，点击 <code>object_detection_tutorial.ipynb</code> 文件，进入打开的新标签，点击“<strong>Cell</strong>”中的“<strong>Run All</strong>”，耐心等待几 ~ 十几分钟（因为它需要下载相应的模型），将会在浏览器下方显示检测结果。</p><p>　　截止本文完成前，该API公开的有以下几个模型：</p><table><thead><tr class="header"><th>Model name</th><th>Speed (ms)</th><th>COCO mAP<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></th><th>Outputs</th></tr></thead><tbody><tr class="odd"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_08.tar.gz">ssd_mobilenet_v1_coco</a></td><td>30</td><td>21</td><td>Boxes</td></tr><tr class="even"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2017_11_08.tar.gz">ssd_inception_v2_coco</a></td><td>42</td><td>24</td><td>Boxes</td></tr><tr class="odd"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2017_11_08.tar.gz">faster_rcnn_inception_v2_coco</a></td><td>58</td><td>28</td><td>Boxes</td></tr><tr class="even"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2017_11_08.tar.gz">faster_rcnn_resnet50_coco</a></td><td>89</td><td>30</td><td>Boxes</td></tr><tr class="odd"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_lowproposals_coco_2017_11_08.tar.gz">faster_rcnn_resnet50_lowproposals_coco</a></td><td>64</td><td></td><td>Boxes</td></tr><tr class="even"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/rfcn_resnet101_coco_2017_11_08.tar.gz">rfcn_resnet101_coco</a></td><td>92</td><td>30</td><td>Boxes</td></tr><tr class="odd"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2017_11_08.tar.gz">faster_rcnn_resnet101_coco</a></td><td>106</td><td>32</td><td>Boxes</td></tr><tr class="even"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_lowproposals_coco_2017_11_08.tar.gz">faster_rcnn_resnet101_lowproposals_coco</a></td><td>82</td><td></td><td>Boxes</td></tr><tr class="odd"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_coco_2017_11_08.tar.gz">faster_rcnn_inception_resnet_v2_atrous_coco</a></td><td>620</td><td>37</td><td>Boxes</td></tr><tr class="even"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2017_11_08.tar.gz">faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco</a></td><td>241</td><td></td><td>Boxes</td></tr><tr class="odd"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_lowproposals_coco_2017_11_08.tar.gz">faster_rcnn_nas</a></td><td>1833</td><td>43</td><td>Boxes</td></tr><tr class="even"><td><a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_lowproposals_coco_2017_11_08.tar.gz">faster_rcnn_nas_lowproposals_coco</a></td><td>540</td><td></td><td>Boxes</td></tr></tbody></table><p>　　根据上述模型可推知，利用该 API 可能只能训练 Faster-RCNN、R-FCN 和 SSD 三种算法的模型。</p><p>接下来介绍如何使用该 API 来训练自己的模型进行物体检测。</p><h2 id="实践篇">实践篇</h2><h3 id="数据准备篇">数据准备篇</h3><p>　　既然要训练自己的模型，当然要准备相应的数据，而 TensorFlow 有其独特的输入数据格式 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_guides/python/python_io#tfrecords_format_details">TFRecord</a>，所以通常还要将自己的数据转换成 TFRecord 格式以输入 TensorFlow 中进行训练。以 <a target="_blank" rel="noopener" href="https://github.com/datitran">datitran</a>/<a target="_blank" rel="noopener" href="https://github.com/datitran/raccoon_dataset"><strong>raccoon_dataset</strong></a> 数据集为例，该作者在 Google image 上收集了 200 张 Raccoon 图片，用 <a target="_blank" rel="noopener" href="https://github.com/tzutalin/labelImg">LabelImg</a> 对这些图片进行标记，并将标记以 PASCAL VOC 格式保存为 xml 文件。作者在文中也提到了另一个图片标记工具 <a target="_blank" rel="noopener" href="https://github.com/christopher5106/FastAnnotationTool">FIAT (Fast Image Data Annotation Tool)</a> 。保存为 PASCAL VOC 格式的 xml 文件之后，可以使用 object_detection 文件夹中的 <a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/blob/master/research/object_detection/create_pascal_tf_record.py">create_pascal_tf_record.py</a> 文件将数据转化为 TFRecord 格式，用法为：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false" data-lang="PYTHON"><div class="code-copy"></div><figure class="highlight hljs python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./create_pascal_tf_record --data_dir=/home/user/VOCdevkit \</span><br><span class="line">        --year=VOC2012 \</span><br><span class="line">        --output_path=/home/user/pascal.record</span><br></pre></td></tr></table></figure></div><p>当然也可以使用 datitran 作者提供的 <a target="_blank" rel="noopener" href="https://github.com/datitran/raccoon_dataset/blob/master/xml_to_csv.py">xml_to_csv.py</a> 文件将 xml 文件先转化为 csv 文件，再利用 <a target="_blank" rel="noopener" href="https://github.com/datitran/raccoon_dataset/blob/master/generate_tfrecord.py">generate_tfrecord.py</a> 文件将 csv 文件转化成 TFRecord 格式文件。</p><p>　　注意，使用 xml_to_csv.py 和 generate_tfrecord.py 其文件结构应该是这样的：</p><blockquote><p>.<br>├── annotations<br>├── generate_tfrecord.py<br>├── images<br>└── xml_to_csv.py</p><p>2 directories, 2 files</p></blockquote><p>其中 images 文件夹存的是 jpg 图片，annotations 文件夹存的是 xml 标签文件。generate_tfrecord.py 文件中的：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false" data-lang="PYTHON"><div class="code-copy"></div><figure class="highlight hljs python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">class_text_to_int</span>(<span class="params">row_label</span>):</span></span><br><span class="line">    <span class="keyword">if</span> row_label == <span class="string">&#x27;raccoon&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></table></figure></div><p>其中的 <code>raccoon</code> 注意要改成自己的类别标签。如此，数据的问题就解决了。</p><h3 id="训练篇">训练篇</h3><p>　　然后就是正式开始训练了，以 Faster-RCNN 算法为例。首先准备相应的数据，Shaun 准备的数据文件结构如下：</p><blockquote><p>TensorFlowObjectDetectionAPITest<br>├── data<br>│ 　├── model.ckpt.data-00000-of-00001<br>│ 　├── model.ckpt.index<br>│ 　├── model.ckpt.meta<br>│ 　├── object_label_map.pbtxt<br>│ 　├── test.record<br>│ 　└── train.record<br>├── eval<br>├── eval.py<br>├── export_inference_graph.py<br>├── faster_rcnn_resnet101_coco.config<br>├── model<br>├── train<br>└── train.py</p><p>4 directories, 10 files</p></blockquote><p>其中，<strong>TensorFlowObjectDetectionAPITest</strong> 为项目文件夹，该 <em>project</em> 在此文件夹下运行；</p><p><strong>data</strong> 文件夹中三个 <strong>model.ckpt</strong> 文件：<strong>model.ckpt.data-00000-of-00001</strong>、<strong>model.ckpt.index</strong> 和 <strong>model.ckpt.meta</strong> 来自 <a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_2017_11_08.tar.gz"><em>faster_rcnn_resnet101_coco</em></a> 模型，用来初始化网络参数；</p><p><strong>object_label_map.pbtxt</strong> 文件内容如下：</p><blockquote><p>item { ​ id: 1 ​ name: 'raccoon' }</p></blockquote><p>将其中的 <code>raccoon</code> 改成自己的类别标签，如果有多个类别标签则可以参考 <code>object_detection\data</code> 文件夹中的 <em><code>pascal_label_map.pbtxt</code></em> 文件格式；</p><p><strong>test.record</strong> 和 <strong>train.record</strong> 是生成的 TFRecord 数据，分别为待输入的测试数据和训练数据；</p><p><strong>eval </strong>文件夹为空文件夹用来输出测试结果；<strong>train</strong> 文件夹为空文件夹用来输出训练结果（包括checkpoint文件和最终的模型文件）；</p><p><strong>faster_rcnn_resnet101_coco.config</strong> 为配置文件，包括各种参数和输入输出数据的配置，其来自 <code>object_detection\samples\configs</code> 文件夹中 <em><code>faster_rcnn_resnet101_coco.config</code></em> 文件，在使用时需对其做如下修改：</p><ol type="1"><li><p>首先是 <strong>num_classes</strong>，这是待检测的类别数目，如果只要检测一种，则将其值改为 1；</p></li><li><p><code>fine_tune_checkpoint: "PATH_TO_BE_CONFIGURED/model.ckpt"</code>，将 <code>PATH_TO_BE_CONFIGURED</code> 改为 <code>./data</code>；</p></li><li><p>``` train_input_reader: { tf_record_input_reader { input_path: "PATH_TO_BE_CONFIGURED/mscoco_train.record" } label_map_path: "PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt" }</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false" data-lang="PLAINTEXT"><div class="code-copy"></div><figure class="highlight hljs plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">   将其中的的 `PATH_TO_BE_CONFIGURED/mscoco_train.record` 改为 `./data/train.record`，将其中的 `PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt` 改为 `./data/object_label_map.pbtxt`；</span><br><span class="line"></span><br><span class="line">4. ```</span><br><span class="line">   eval_input_reader: &#123;</span><br><span class="line">     tf_record_input_reader &#123;</span><br><span class="line">       input_path: &quot;PATH_TO_BE_CONFIGURED/mscoco_val.record&quot;</span><br><span class="line">     &#125;</span><br><span class="line">     label_map_path: &quot;PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt&quot;</span><br><span class="line">     shuffle: false</span><br><span class="line">     num_readers: 1</span><br><span class="line">     num_epochs: 1</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></div><p></p><p>将其中的的 <code>PATH_TO_BE_CONFIGURED/mscoco_val.record</code> 改为 <code>./data/test.record</code>，将其中的 <code>PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt</code> 改为 <code>./data/object_label_map.pbtxt</code>；</p></li></ol><p>至于其它的参数可以选择默认，不对其进行修改；</p><p><strong>train.py</strong> 为训练代码，其来自 <code>object_detection/</code> 文件夹中的 <em><code>train.py</code></em>，直接复制出来使用即可，具体用法为：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false" data-lang="BASH"><div class="code-copy"></div><figure class="highlight hljs bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train.py --logtostderr --train_dir=./train --pipeline_config_path=faster_rcnn_resnet101_coco.config</span><br></pre></td></tr></table></figure></div><p>其在运行过程中会在 <strong>train</strong> 文件夹生成一系列训练过程文件，比如 checkpoint、model.ckpt-{num}（{num} 代表训练过程保存的第几个网络模型，一般从 0 开始，包括 .index、.meta和 .data 三个文件）等文件。</p><p><strong>eval.py</strong> 为评估代码，其来自 <code>object_detection/</code> 文件夹中的 <em><code>eval.py</code></em>，直接复制出来使用即可，具体用法为：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false" data-lang="BASH"><div class="code-copy"></div><figure class="highlight hljs bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python eval.py --logtostderr --checkpoint_dir=./train --eval_dir=./<span class="built_in">eval</span> --pipeline_config_path=./faster_rcnn_resnet101_coco.config</span><br></pre></td></tr></table></figure></div><p>其在运行过程中会在 <strong>eval</strong> 文件夹生成一系列评估文件，每个文件对应一个测试 image。</p><p><strong>export_inference_graph.py</strong> 为导出 pb 模型代码，其来自 <code>object_detection/</code> 文件夹中的 <em><code>export_inference_graph.py</code></em>，直接复制出来使用即可，具体用法为：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false" data-lang="BASH"><div class="code-copy"></div><figure class="highlight hljs bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python export_inference_graph.py --input_type image_tensor --pipeline_config_path ./faster_rcnn_resnet101_coco.config --trained_checkpoint_prefix ./train/model.ckpt-18298 --output_directory ./model</span><br></pre></td></tr></table></figure></div><p>其中 <code>model.ckpt-18298</code> 表示使用第 18298 次保存的网络模型导出 pb 模型文件，导出的模型文件保存在 <strong>model</strong> 文件夹，主要有一下几个文件：</p><blockquote><p>- graph.pbtxt</p><p>- model.ckpt.data-00000-of-00001</p><p>- model.ckpt.info</p><p>- model.ckpt.meta</p><p>- frozen_inference_graph.pb</p></blockquote><p>其中 frozen_inference_graph.pb 就是训练成功用来检测目标的模型。</p><p>　　TensorFlow 训练时可以随时查看训练过程，如损失函数的值下降曲线等，所用命令为：在命令行中切换目录至 project 运行目录，即 train.py 所在文件夹，Shaun 这里即 <em>TensorFlowObjectDetectionAPITest</em> 文件夹，输入：<code>tensorboard --logdir=./</code>，等待片刻，在浏览器地址栏输入：<code>http://localhost:6006/</code>，即可看到训练过程曲线。</p><h3 id="检测篇">检测篇</h3><p>　　检测结果使用 opencv 窗口显示（至于 python 中 opencv 的使用详见下一篇（<a href="https://cniter.github.io/posts/5f54aa2c.html">PyQt5使用小结</a>）），具体调用自己训练的模型进行检测的 Python 代码（该代码为 eli 大佬参考 <code>object_detection</code> 文件夹中的 <em><code>object_detection_tutorial.ipynb</code></em>（该文件可在 jupyter 中查看）改的）为：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false" data-lang="PYTHON"><div class="code-copy"></div><figure class="highlight hljs python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> label_map_util</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> visualization_utils <span class="keyword">as</span> vis_util</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Detector</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.PATH_TO_CKPT = <span class="string">r&#x27;./model/frozen_inference_graph.pb&#x27;</span>    <span class="comment"># 选择模型</span></span><br><span class="line">        self.PATH_TO_LABELS = <span class="string">r&#x27;./data/object_label_map.pbtxt&#x27;</span>      <span class="comment"># 选择类别标签文件</span></span><br><span class="line">        self.NUM_CLASSES = <span class="number">1</span></span><br><span class="line">        self.detection_graph = self._load_model()</span><br><span class="line">        self.category_index = self._load_label_map()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_load_model</span>(<span class="params">self</span>):</span></span><br><span class="line">        detection_graph = tf.Graph()</span><br><span class="line">        <span class="keyword">with</span> detection_graph.as_default():</span><br><span class="line">            od_graph_def = tf.GraphDef()</span><br><span class="line">            <span class="keyword">with</span> tf.gfile.GFile(self.PATH_TO_CKPT, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> fid:</span><br><span class="line">                serialized_graph = fid.read()</span><br><span class="line">                od_graph_def.ParseFromString(serialized_graph)</span><br><span class="line">                tf.import_graph_def(od_graph_def, name=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> detection_graph</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_load_label_map</span>(<span class="params">self</span>):</span></span><br><span class="line">        label_map = label_map_util.load_labelmap(self.PATH_TO_LABELS)</span><br><span class="line">        categories = label_map_util.convert_label_map_to_categories(label_map,</span><br><span class="line">                                                                    max_num_classes=self.NUM_CLASSES,</span><br><span class="line">                                                                    use_display_name=<span class="literal">True</span>)</span><br><span class="line">        category_index = label_map_util.create_category_index(categories)</span><br><span class="line">        <span class="keyword">return</span> category_index</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detect</span>(<span class="params">self, image</span>):</span></span><br><span class="line">        <span class="keyword">with</span> self.detection_graph.as_default():</span><br><span class="line">            <span class="keyword">with</span> tf.Session(graph=self.detection_graph) <span class="keyword">as</span> sess:</span><br><span class="line">                <span class="comment"># Expand dimensions since the model expects images to have shape: [1, None, None, 3]</span></span><br><span class="line">                image_np_expanded = np.expand_dims(image, axis=<span class="number">0</span>)</span><br><span class="line">                image_tensor = self.detection_graph.get_tensor_by_name(<span class="string">&#x27;image_tensor:0&#x27;</span>)</span><br><span class="line">                boxes = self.detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_boxes:0&#x27;</span>)</span><br><span class="line">                scores = self.detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_scores:0&#x27;</span>)</span><br><span class="line">                classes = self.detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_classes:0&#x27;</span>)</span><br><span class="line">                num_detections = self.detection_graph.get_tensor_by_name(<span class="string">&#x27;num_detections:0&#x27;</span>)</span><br><span class="line">                <span class="comment"># Actual detection.</span></span><br><span class="line">                (boxes, scores, classes, num_detections) = sess.run(</span><br><span class="line">                    [boxes, scores, classes, num_detections],</span><br><span class="line">                    feed_dict=&#123;image_tensor: image_np_expanded&#125;)</span><br><span class="line">                <span class="comment"># Visualization of the results of a detection.</span></span><br><span class="line">                vis_util.visualize_boxes_and_labels_on_image_array(</span><br><span class="line">                    image,</span><br><span class="line">                    np.squeeze(boxes),</span><br><span class="line">                    np.squeeze(classes).astype(np.int32),</span><br><span class="line">                    np.squeeze(scores),</span><br><span class="line">                    self.category_index,</span><br><span class="line">                    use_normalized_coordinates=<span class="literal">True</span>,</span><br><span class="line">                    line_thickness=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line">        cv2.namedWindow(<span class="string">&quot;detection&quot;</span>, cv2.WINDOW_NORMAL)</span><br><span class="line">        cv2.imshow(<span class="string">&quot;detection&quot;</span>, image)</span><br><span class="line">        cv2.waitKey(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    image = cv2.imread(<span class="string">&#x27;./test_img.jpg&#x27;</span>) <span class="comment"># 选择待检测的图片</span></span><br><span class="line">    detector = Detector()</span><br><span class="line">    detector.detect(image)</span><br></pre></td></tr></table></figure></div><h2 id="后记">后记</h2><p>　　经过这次 TensorFlow 训练，感觉深度学习 真tm 吃硬件，费时间，也难怪神经网络理论出来几十年之后才火，当年的硬件根本无法支持这么大的计算量。</p><h2 id="附录">附录</h2><p>最后附上 datitran 作者提供的 xml_to_csv.py 文件源码和 generate_tfrecord.py 文件源码：</p><p><strong>xml_to_csv.py 源码</strong>如下：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false" data-lang="PYTHON"><div class="code-copy"></div><figure class="highlight hljs python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xml_to_csv</span>(<span class="params">path</span>):</span></span><br><span class="line">    xml_list = []</span><br><span class="line">    <span class="keyword">for</span> xml_file <span class="keyword">in</span> glob.glob(path + <span class="string">&#x27;/*.xml&#x27;</span>):</span><br><span class="line">        tree = ET.parse(xml_file)</span><br><span class="line">        root = tree.getroot()</span><br><span class="line">        <span class="keyword">for</span> member <span class="keyword">in</span> root.findall(<span class="string">&#x27;object&#x27;</span>):</span><br><span class="line">            value = (root.find(<span class="string">&#x27;filename&#x27;</span>).text,</span><br><span class="line">                     <span class="built_in">int</span>(root.find(<span class="string">&#x27;size&#x27;</span>)[<span class="number">0</span>].text),</span><br><span class="line">                     <span class="built_in">int</span>(root.find(<span class="string">&#x27;size&#x27;</span>)[<span class="number">1</span>].text),</span><br><span class="line">                     member[<span class="number">0</span>].text,</span><br><span class="line">                     <span class="built_in">int</span>(member[<span class="number">4</span>][<span class="number">0</span>].text),</span><br><span class="line">                     <span class="built_in">int</span>(member[<span class="number">4</span>][<span class="number">1</span>].text),</span><br><span class="line">                     <span class="built_in">int</span>(member[<span class="number">4</span>][<span class="number">2</span>].text),</span><br><span class="line">                     <span class="built_in">int</span>(member[<span class="number">4</span>][<span class="number">3</span>].text)</span><br><span class="line">                     )</span><br><span class="line">            xml_list.append(value)</span><br><span class="line">    column_name = [<span class="string">&#x27;filename&#x27;</span>, <span class="string">&#x27;width&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;class&#x27;</span>, <span class="string">&#x27;xmin&#x27;</span>, <span class="string">&#x27;ymin&#x27;</span>, <span class="string">&#x27;xmax&#x27;</span>, <span class="string">&#x27;ymax&#x27;</span>]</span><br><span class="line">    xml_df = pd.DataFrame(xml_list, columns=column_name)</span><br><span class="line">    <span class="keyword">return</span> xml_df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    image_path = os.path.join(os.getcwd(), <span class="string">&#x27;annotations&#x27;</span>)</span><br><span class="line">    xml_df = xml_to_csv(image_path)</span><br><span class="line">    xml_df.to_csv(<span class="string">&#x27;raccoon_labels.csv&#x27;</span>, index=<span class="literal">None</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Successfully converted xml to csv.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure></div><p><strong>generate_tfrecord.py 文件源码</strong> 如下：</p><div class="highlight-wrap" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" contenteditable="false" data-lang="PYTHON"><div class="code-copy"></div><figure class="highlight hljs python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Usage:</span></span><br><span class="line"><span class="string">  # From tensorflow/models/</span></span><br><span class="line"><span class="string">  # Create train data:</span></span><br><span class="line"><span class="string">  python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record</span></span><br><span class="line"><span class="string">  # Create test data:</span></span><br><span class="line"><span class="string">  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> dataset_util</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple, OrderedDict</span><br><span class="line"></span><br><span class="line">flags = tf.app.flags</span><br><span class="line">flags.DEFINE_string(<span class="string">&#x27;csv_input&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;Path to the CSV input&#x27;</span>)</span><br><span class="line">flags.DEFINE_string(<span class="string">&#x27;output_path&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;Path to output TFRecord&#x27;</span>)</span><br><span class="line">FLAGS = flags.FLAGS</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># TO-DO replace this with label map</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">class_text_to_int</span>(<span class="params">row_label</span>):</span></span><br><span class="line">    <span class="keyword">if</span> row_label == <span class="string">&#x27;raccoon&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split</span>(<span class="params">df, group</span>):</span></span><br><span class="line">    data = namedtuple(<span class="string">&#x27;data&#x27;</span>, [<span class="string">&#x27;filename&#x27;</span>, <span class="string">&#x27;object&#x27;</span>])</span><br><span class="line">    gb = df.groupby(group)</span><br><span class="line">    <span class="keyword">return</span> [data(filename, gb.get_group(x)) <span class="keyword">for</span> filename, x <span class="keyword">in</span> <span class="built_in">zip</span>(gb.groups.keys(), gb.groups)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tf_example</span>(<span class="params">group, path</span>):</span></span><br><span class="line">    <span class="keyword">with</span> tf.gfile.GFile(os.path.join(path, <span class="string">&#x27;&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(group.filename)), <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> fid:</span><br><span class="line">        encoded_jpg = fid.read()</span><br><span class="line">    encoded_jpg_io = io.BytesIO(encoded_jpg)</span><br><span class="line">    image = Image.<span class="built_in">open</span>(encoded_jpg_io)</span><br><span class="line">    width, height = image.size</span><br><span class="line"></span><br><span class="line">    filename = group.filename.encode(<span class="string">&#x27;utf8&#x27;</span>)</span><br><span class="line">    image_format = <span class="string">b&#x27;jpg&#x27;</span></span><br><span class="line">    xmins = []</span><br><span class="line">    xmaxs = []</span><br><span class="line">    ymins = []</span><br><span class="line">    ymaxs = []</span><br><span class="line">    classes_text = []</span><br><span class="line">    classes = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> group.<span class="built_in">object</span>.iterrows():</span><br><span class="line">        xmins.append(row[<span class="string">&#x27;xmin&#x27;</span>] / width)</span><br><span class="line">        xmaxs.append(row[<span class="string">&#x27;xmax&#x27;</span>] / width)</span><br><span class="line">        ymins.append(row[<span class="string">&#x27;ymin&#x27;</span>] / height)</span><br><span class="line">        ymaxs.append(row[<span class="string">&#x27;ymax&#x27;</span>] / height)</span><br><span class="line">        classes_text.append(row[<span class="string">&#x27;class&#x27;</span>].encode(<span class="string">&#x27;utf8&#x27;</span>))</span><br><span class="line">        classes.append(class_text_to_int(row[<span class="string">&#x27;class&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    tf_example = tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">        <span class="string">&#x27;image/height&#x27;</span>: dataset_util.int64_feature(height),</span><br><span class="line">        <span class="string">&#x27;image/width&#x27;</span>: dataset_util.int64_feature(width),</span><br><span class="line">        <span class="string">&#x27;image/filename&#x27;</span>: dataset_util.bytes_feature(filename),</span><br><span class="line">        <span class="string">&#x27;image/source_id&#x27;</span>: dataset_util.bytes_feature(filename),</span><br><span class="line">        <span class="string">&#x27;image/encoded&#x27;</span>: dataset_util.bytes_feature(encoded_jpg),</span><br><span class="line">        <span class="string">&#x27;image/format&#x27;</span>: dataset_util.bytes_feature(image_format),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/xmin&#x27;</span>: dataset_util.float_list_feature(xmins),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/xmax&#x27;</span>: dataset_util.float_list_feature(xmaxs),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/ymin&#x27;</span>: dataset_util.float_list_feature(ymins),</span><br><span class="line">        <span class="string">&#x27;image/object/bbox/ymax&#x27;</span>: dataset_util.float_list_feature(ymaxs),</span><br><span class="line">        <span class="string">&#x27;image/object/class/text&#x27;</span>: dataset_util.bytes_list_feature(classes_text),</span><br><span class="line">        <span class="string">&#x27;image/object/class/label&#x27;</span>: dataset_util.int64_list_feature(classes),</span><br><span class="line">    &#125;))</span><br><span class="line">    <span class="keyword">return</span> tf_example</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">_</span>):</span></span><br><span class="line">    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)</span><br><span class="line">    path = os.path.join(os.getcwd(), <span class="string">&#x27;images&#x27;</span>)</span><br><span class="line">    examples = pd.read_csv(FLAGS.csv_input)</span><br><span class="line">    grouped = split(examples, <span class="string">&#x27;filename&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> group <span class="keyword">in</span> grouped:</span><br><span class="line">        tf_example = create_tf_example(group, path)</span><br><span class="line">        writer.write(tf_example.SerializeToString())</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line">    output_path = os.path.join(os.getcwd(), FLAGS.output_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Successfully created the TFRecords: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(output_path))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure></div><h2 id="参考资料">参考资料</h2><p>[1] <a target="_blank" rel="noopener" href="http://blog.csdn.net/xiaoxiao123jun/article/details/76605928">对于谷歌开源的TensorFlow Object Detection API视频物体识别系统实现教程</a></p><p>[2] <a target="_blank" rel="noopener" href="http://blog.csdn.net/c20081052/article/details/77608954">TensorFlow学习——Tensorflow Object Detection API（win10，CPU）</a></p><p>[3] <a target="_blank" rel="noopener" href="https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9">How to train your own Object Detector with TensorFlow’s Object Detector API</a></p><p>[4] <a target="_blank" rel="noopener" href="http://rensanning.iteye.com/blog/2381885">TensorFlow 之 物体检测</a>（<a target="_blank" rel="noopener" href="http://rensanning.iteye.com/category/374992" class="uri">http://rensanning.iteye.com/category/374992</a>）</p><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr><ol><li id="fn1" role="doc-endnote"><p>See <a target="_blank" rel="noopener" href="http://cocodataset.org/#detections-eval">MSCOCO evaluation protocol</a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section></section></article><div class="copyright"><p><span>本文标题：</span> <a href="/posts/82d3b275.html">TensorFlow Object Detection API使用小结</a></p><p><span>文章作者：</span> <a href="/" title="访问 Shaun 的个人博客" data-toggle="tooltip">Shaun</a></p><p><span>发布时间：</span> 2017年11月11日 - 21时52分</p><p><span>最后更新：</span> 2021年12月18日 - 19时54分</p><p><span>原始链接：</span> <a class="post-url" href="/posts/82d3b275.html" title="TensorFlow Object Detection API使用小结" data-toggle="tooltip">http://cniter.github.io/posts/82d3b275.html </a><span class="copy-path" data-clipboard-text="原文: http://cniter.github.io/posts/82d3b275.html　　作者: Shaun" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span></p><p><span>许可协议：</span> <i class="fa fa-creative-commons"></i> <a rel="license noopener" target="_blank" href="//creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" title="署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0)" target="_blank" data-toggle="tooltip">"署名-非商业性使用-相同方式共享 4.0 国际" </a>转载请保留原文链接及作者。</p></div><nav id="article-nav"><a href="/posts/5f54aa2c.html" id="article-nav-newer" class="article-nav-link-wrap"><strong class="article-nav-caption">&lt;</strong><div class="article-nav-title">&nbsp; PyQt5使用小结</div></a><a href="/posts/2a3d46b0.html" id="article-nav-older" class="article-nav-link-wrap"><div class="article-nav-title">C语言中整型提升问题 &nbsp;</div><strong class="article-nav-caption">&gt;</strong></a></nav><div class="bdsharebuttonbox"><a href="#" class="fx fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博" data-toggle="tooltip"></a> <a href="#" class="fx fa fa-weixin bds_weixin" data-cmd="weixin" title="分享到微信" data-toggle="tooltip"></a> <a href="#" class="fx fa fa-qq bds_sqq" data-cmd="sqq" title="分享到QQ好友" data-toggle="tooltip"></a> <a href="#" class="fx fa fa-facebook-official bds_fbook" data-cmd="fbook" title="分享到Facebook" data-toggle="tooltip"></a> <a href="#" class="fx fa fa-twitter bds_twi" data-cmd="twi" title="分享到Twitter" data-toggle="tooltip"></a> <a href="#" class="fx fa fa-linkedin bds_linkedin" data-cmd="linkedin" title="分享到linkedin" data-toggle="tooltip"></a> <a href="#" class="fx fa fa-files-o bds_copy" data-cmd="copy" title="复制网址" data-toggle="tooltip"></a> <a href="#" class="fx fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享" data-toggle="tooltip"></a></div><script>with(window._bd_share_config={common:{bdSnsKey:{},bdText:"TensorFlow Object Detection API使用小结 | Shaun's Space",bdMini:"2",bdMiniList:!1,bdPic:"",bdStyle:"2",bdSize:"24"},share:{}},document)(getElementsByTagName("head")[0]||body).appendChild(createElement("script")).src="/plugins/baidushare/static/api/js/share.js"+"?v=89860593.js?cdnversion="+~(-new Date/36e5)</script><div id="comments" class="div-border"><script src="https://giscus.app/client.js" data-repo="cniter/cniter.github.io" data-repo-id="MDEwOlJlcG9zaXRvcnkxMTQ0NjAxMDc=" data-category="Announcements" data-category-id="DIC_kwDOBtKFy84CkXvq" data-mapping="pathname" data-strict="0" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="https://cniter.github.io/css/giscus-chi.css" data-lang="zh-CN" data-loading="lazy" crossorigin="anonymous" async></script></div><script>let articleToc='<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E7%AF%87"><span class="toc-number">2.</span> <span class="toc-text">准备篇</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E8%B7%B5%E7%AF%87"><span class="toc-number">3.</span> <span class="toc-text">实践篇</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%E7%AF%87"><span class="toc-number">3.1.</span> <span class="toc-text">数据准备篇</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%AF%87"><span class="toc-number">3.2.</span> <span class="toc-text">训练篇</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%80%E6%B5%8B%E7%AF%87"><span class="toc-number">3.3.</span> <span class="toc-text">检测篇</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E8%AE%B0"><span class="toc-number">4.</span> <span class="toc-text">后记</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%84%E5%BD%95"><span class="toc-number">5.</span> <span class="toc-text">附录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">6.</span> <span class="toc-text">参考资料</span></a></li></ol>';$(window).on("load",(function(){$(".toc-title").text("文章目录"),$(".post-list").replaceWith(articleToc);var s=$("#toc .toc-item:has(> .toc-child)"),c=s.children(".toc-link");s.prepend("<i class='fa fa-caret-down'></i><i class='fa fa-caret-right'></i>");$(".toc-item > .fa-caret-down");var t=$(".toc-item > .fa-caret-right");t.addClass("hide");$("#toc .toc-item > i").click((function(){$(this).siblings(".toc-child").slideToggle(100),$(this).toggleClass("hide"),$(this).siblings("i").toggleClass("hide")})),$(".toc-item > .fa-caret-down");t.addClass("hide");c.dblclick((function(){$(this).siblings(".toc-child").hide(100),$(this).siblings("i").toggleClass("hide")})),c.click((function(){var s=$(this).siblings(".toc-child");s.is(":hidden")&&(s.show(100),$(this).siblings("i").toggleClass("hide"))})),function(){var s=$(".toc-item > .fa-caret-right"),t=$(".toc-item > .fa-caret-down"),a=c.next(".toc-child"),l=$("#toc .toc-title");c.length&&(l.addClass("clickable"),l.click((function(){a.is(":hidden")?(a.show(150),s.removeClass("hide"),t.addClass("hide")):(a.hide(100),s.addClass("hide"),t.removeClass("hide"))})))}()}))</script></main><div id="site-tool"><div class="scroll"><a href="#header"><i class="fa fa-arrow-up"></i></a> <a href="#footer"><i class="fa fa-arrow-down"></i></a></div><div></div></div><aside id="right-col" class="col-lg-3 col-sm-12"><div id="sidebar-sticky--bottom"></div><div id="sidebar"><header class="author-info div-border"><a href="/"><img class="header-avatar" src="/img/avatar.jpg"></a><h1 class="header-author"><a href="/" title="Hi Mate" data-toggle="tooltip">Shaun</a></h1><p class="header-slogan">求知！ 视界！ 未来！ ↖(^ω^)↗</p><div class="social-info"><a class="social-icon" target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=qNvAyd3G0d3JxujOx9DFycHEhsvHxQ" title="envelope" data-toggle="tooltip"><i class="fa fa-envelope" aria-hidden="true"></i> </a><a class="social-icon" target="_blank" href="https://github.com/cniter" title="github" data-toggle="tooltip"><i class="fa fa-github" aria-hidden="true"></i> </a><a class="social-icon" target="_blank" href="/atom.xml" title="rss" data-toggle="tooltip"><i class="fa fa-rss" aria-hidden="true"></i> </a><a class="social-icon" target="_blank" href="http://sighttp.qq.com/authd?IDKEY=4faf682653b3b7f5f47b9cb6d2bb8b81de8fa7a8fb8cee12" title="qq" data-toggle="tooltip"><i class="fa fa-qq" aria-hidden="true"></i></a></div></header><div class="search div-border" title="搜索" data-toggle="tooltip"><form id="search-form"><input type="text" id="local-search--input" name="q" results="0" placeholder=" Search..." autocomplete="off" autocorrect="off"> <i class="fa fa-times" onclick="resetSearch()"></i></form><div id="local-search--result"></div><p class="no-result">No results found</p></div><div id="tagcloud" class="tagcanvas div-border" title="标签" data-toggle="tooltip"><canvas width="200" height="200" id="tagcloud-canvas"><p>Anything in here will be replaced on browsers that support the canvas element</p><ul><li><a href="/tags/algorithm/" data-weight="8">algorithm</a></li><li><a href="/tags/android/" data-weight="2">android</a></li><li><a href="/tags/bigdata/" data-weight="2">bigdata</a></li><li><a href="/tags/c-cpp/" data-weight="6">c/cpp</a></li><li><a href="/tags/clustering/" data-weight="1">clustering</a></li><li><a href="/tags/container/" data-weight="1">container</a></li><li><a href="/tags/css/" data-weight="1">css</a></li><li><a href="/tags/cv/" data-weight="5">cv</a></li><li><a href="/tags/devtool/" data-weight="1">devtool</a></li><li><a href="/tags/ffmpeg/" data-weight="1">ffmpeg</a></li><li><a href="/tags/geomesa/" data-weight="1">geomesa</a></li><li><a href="/tags/geometry/" data-weight="4">geometry</a></li><li><a href="/tags/gfw/" data-weight="1">gfw</a></li><li><a href="/tags/github/" data-weight="1">github</a></li><li><a href="/tags/gl/" data-weight="1">gl</a></li><li><a href="/tags/golang/" data-weight="2">golang</a></li><li><a href="/tags/hexo/" data-weight="8">hexo</a></li><li><a href="/tags/http/" data-weight="1">http</a></li><li><a href="/tags/integration/" data-weight="1">integration</a></li><li><a href="/tags/java/" data-weight="2">java</a></li><li><a href="/tags/k8s/" data-weight="1">k8s</a></li><li><a href="/tags/language/" data-weight="3">language</a></li><li><a href="/tags/latex/" data-weight="1">latex</a></li><li><a href="/tags/mapbox/" data-weight="1">mapbox</a></li><li><a href="/tags/markdown/" data-weight="1">markdown</a></li><li><a href="/tags/matlab/" data-weight="2">matlab</a></li><li><a href="/tags/network/" data-weight="1">network</a></li><li><a href="/tags/note/" data-weight="7">note</a></li><li><a href="/tags/numerical/" data-weight="1">numerical</a></li><li><a href="/tags/opencv/" data-weight="11">opencv</a></li><li><a href="/tags/opendrive/" data-weight="1">opendrive</a></li><li><a href="/tags/opengl/" data-weight="1">opengl</a></li><li><a href="/tags/python/" data-weight="1">python</a></li><li><a href="/tags/qt/" data-weight="2">qt</a></li><li><a href="/tags/record/" data-weight="14">record</a></li><li><a href="/tags/search/" data-weight="1">search</a></li><li><a href="/tags/segmentation/" data-weight="2">segmentation</a></li><li><a href="/tags/tensorflow/" data-weight="1">tensorflow</a></li><li><a href="/tags/thought/" data-weight="3">thought</a></li><li><a href="/tags/unix-like/" data-weight="3">unix-like</a></li><li><a href="/tags/vscode/" data-weight="1">vscode</a></li></ul></canvas><script src="/plugins/TagCanvas/jquery.tagcanvas.min.js" type="text/javascript"></script><script type="text/javascript">$(document).ready((function(){$("#tagcloud-canvas").tagcanvas({initial:[.1,-.1],activeCursor:'url("/img/cursor/link.cur"), auto',reverse:!0,depth:.75,weight:!0,weightFrom:"data-weight",weightMode:"both",weightSizeMin:15,weightSizeMax:50})||$("#tagcloud").hide()}))</script></div><div class="friends div-border" title="友链" data-toggle="tooltip"><a target="_blank" class="friends-link" href="https://cniter.github.io">Shaun&#39;s Space</a></div><div class="revolvermaps div-border" title="访客" data-toggle="tooltip"><a target="_blank" rel="noopener" href="http://livetrafficfeed.com/3d-visitor-maps" id="LTF_3d_maps">Live 3D Globes Visitor</a><script type="text/javascript" src="//cdn.livetrafficfeed.com/static/3d-maps/live.js?o=000080&amp;l=339966&amp;b=339966&amp;c=ff0000&amp;root=1&amp;timezone=Asia%2FShanghai&amp;s=" async></script></div></div><div class="toc-card"><div class="toc-card--head"><i class="fa fa-angle-up" aria-hidden="true"></i></div><div id="toc" class="toc-card--content"><strong class="toc-title">文章列表</strong><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/posts/36b343ff.html">HTTP 超时浅见</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/6be57d7f.html">关于中学的学习方法</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/619020f7.html">VNSWRR 算法浅解</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/2eb69b33.html">记一次资源不释放的问题</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/dbbe01e5.html">社畜三年，风雨兼程</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/8e1d1e1d.html">2021 年小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/4b1f50ff.html">M1 个人配置</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/9c9b4035.html">Scala 多线程编程小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/720275bd.html">Google S2 Geometry 浅解</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/55e674ff.html">K8S 应用开发指北</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/81321445.html">OpenGL坐标系统与渲染管线</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/8d3d87a2.html">Scala 学习小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/28416d7c.html">2020年小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/b59e3e7b.html">Linux服务器运维文档</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/489fa7b3.html">时空查询之ECQL</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/9978824c.html">GeoMesa踩坑指北</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/3692cd6.html">IDEA使用Docker环境开发调试</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/af5e9ace.html">大数据环境搭建笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/ae780057.html">设计模式浅谈</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/eee1c041.html">积分计算</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/a5661762.html">Geometry增量更新</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/e225d8fd.html">Mapbox显示GeoServer地图</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/3d8ab974.html">Docker使用小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/6694a214.html">空间中三角形与三角形相交</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/5315fcfd.html">计算几何基础</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/b7d79231.html">OpenDrive解析小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/39a3c99e.html">一张纹理做天空盒</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/a250bb21.html">Windows Terminal 尝鲜小记</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/ae5f9dce.html">读大学</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/cf97ba7c.html">2019，既是结束又是开始</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/ff29de94.html">快速判断三角形与长方体相交</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/70a807da.html">网页菜单纯 css 实现</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/abe58f8c.html">个人游记</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/26d437be.html">hexo-theme-chi主题更新小记</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/3578e309.html">［译］为什么深度学习没有取代传统的计算机视觉</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/37b89a23.html">再也不见，18年</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/ac4679b5.html">hexo-theme-chi主题开发小记</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/64889158.html">Matlab和OpenCV混合编程小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/be7949e4.html">Android实践小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/fc1165b7.html">C++数组中的坑</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/cafdd60d.html">Android开发环境配置</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/27a4c8b6.html">Windows实用技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/6315717b.html">FFmpeg提取与合并命令使用小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/fd823bf9.html">解决VSCode使用Cmder作为默认终端问题</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/fddd1e17.html">图割算法之NCuts浅见</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/c42ff8d4.html">图割算法之Graph Cuts浅见</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/b93d943b.html">C++中static用法小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/8fb9f004.html">斐波那契数列的三种写法</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/bcdf334e.html">LaTex语法指北</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/982ff584.html">搜索技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/7cebf0ee.html">17年走了，18年来了</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/e124baa1.html">矩阵的应用之图像仿射变换</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/aef52be2.html">本人常用小工具安利</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/376168c6.html">解决无法打开某个网页问题</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/5f54aa2c.html">PyQt5使用小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/82d3b275.html">TensorFlow Object Detection API使用小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/2a3d46b0.html">C语言中整型提升问题</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/dece8eba.html">TXT数据转OpenCV中的Mat数据</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/e8b35736.html">OpenCV中滑动条和鼠标事件响应操作的使用小结</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/b6fb6109.html">利用回调函数计算函数运行时间</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/df943c4f.html">论如何科学的上网</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/b1e9411b.html">Hexo的SPFK主题修改小记</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/22c3daf1.html">解决Qt中Qlabel显示OpenCV的Mat数据图像产生扭曲现象问题</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/509ee93b.html">解决OpenCV-2.4.11调用摄像头显示拍摄视频出错问题</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/3bc0decc.html">Hexo添加各种小部件</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/fd0f8195.html">OpenCV中显著性检测算法的使用</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/35132cb7.html">OpenCV中Selective Search算法的使用</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/170c76cc.html">别了，漆黑的象牙塔</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/c3f26b1.html">Win10以树形结构显示文件目录结构</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/68065b99.html">ACGN作品个人印象简评</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/4f6225b7.html">Hexo添加站内本地搜索</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/302a6244.html">用OpenCV显示OpenGL图形</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/7df528b4.html">Win10＋VS2013＋CMake-gui编译和配置OpenCV-3.2.0</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/17017530.html">MyThoughts</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/7d5bc07b.html">解决写上篇文档“Hexo+GitHub搭建个人博客”遇到的问题</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/d7965b48.html">Hexo+GitHub搭建个人博客</a></li><li class="post-list-item"><a class="post-list-link" href="/posts/4a17b156.html">Hello World</a></li></ul></div></div></aside></div></div><span id="cursor-trail"></span> <span class="click-halo"></span><footer id="footer" class="text-center"><div class="copyright-info">&copy; 2017 - 2024 <a href="/">Shaun</a></div><span class="site-visitor"><i class="fa fa-user-o" aria-hidden="true"></i> <span id="busuanzi_value_site_uv"><i class="fa fa-spinner fa-spin"></i></span> &nbsp;|&nbsp; <i class="fa fa-eye" aria-hidden="true"></i> <span id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></span> &nbsp;|&nbsp; <i class="fa fa-hand-o-up" aria-hidden="true"></i> <span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span></span><div class="site-info"><a href="http://hexo.io/" target="_blank">Hexo </a>theme <a href="https://github.com/cniter/hexo-theme-chi" target="_blank">Chi </a>by <a href="https://github.com/cniter" target="_blank">Shaun</a></div></footer><script type="text/javascript" async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" integrity="sha256-WUED7NFzpsmHtLO7bswSz4JSfkhE+cD4ncKeOznwFSY=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
            processEscapes: true,
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }

        , TeX: {
            extensions: ["extpfeil.js"]
        }
    });
    
    MathJax.Hub.Queue(function() {
        let all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';                 
        }       
    });</script><script type="text/javascript">const MutationObserver=window.MutationObserver||window.WebKitMutationObserver||window.MozMutationObserver,config={attributes:!0,childList:!0,characterData:!0};let target=document.querySelector("#local-search--result"),$local_search_result=$("#local-search--result"),$no_result=$(".no-result"),observer=new MutationObserver((function(e){e.forEach((function(e){$local_search_result.text()||""==$local_search_result.html()?$no_result.hide():$no_result.show(200)}))})),inputArea=document.querySelector("#local-search--input"),getSearchFile=function(){let e="search.xml";0==e.length&&(e="search.xml"),searchFunc("/"+e,"local-search--input","local-search--result"),observer.observe(target,config)};inputArea.onfocus=function(){getSearchFile()};let $resetButton=$("#search-form .fa-times"),$resultArea=$("#local-search--result");inputArea.oninput=function(){$resetButton.show()};let resetSearch=function(){$resultArea.html(""),document.querySelector("#search-form").reset(),$resetButton.hide(),$no_result.hide(),observer.disconnect()};inputArea.onkeydown=function(e){if(13==e.keyCode)return!1};let searchFunc=function(e,t,r){"use strict";$.ajax({url:e,dataType:"xml",success:function(e){let n=$("entry",e).map((function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}})).get(),l=document.getElementById(t),s=document.getElementById(r);l.addEventListener("input",(function(){let e='<ul class="search-result--list">',t=this.value.trim().toLowerCase().split(/[\s\-]+/);s.innerHTML="",this.value.trim().length<=0||(n.forEach((function(r){let n=!0,l=r.title.trim().toLowerCase(),s=r.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),c=r.url,o=-1,a=-1,u=-1;if(""!=l&&""!=s&&t.forEach((function(e,t){o=l.indexOf(e),a=s.indexOf(e),o<0&&a<0?n=!1:(a<0&&(a=0),0==t&&(u=a))})),n){e+="<li><a href='"+c+"' class='search-result--title' target='_blank'>> "+l+"</a>";let n=r.content.trim().replace(/<[^>]+>/g,"");if(u>=0){let r=u-6,l=u+6;r<0&&(r=0),0==r&&(l=10),l>n.length&&(l=n.length);let s=n.substr(r,l);t.forEach((function(e){let t=new RegExp(e,"gi");s=s.replace(t,'<em class="search-keyword">'+e+"</em>")})),e+='<p class="search-result">'+s+"...</p>"}}})),s.innerHTML=e)}))}})}</script><script>function loadScript(e,t){let a=document.createElement("script");a.type="text/javascript",a.async=!0,a.readyState?a.onreadystatechange=function(){"loaded"!=a.readyState&&"complete"!=a.readyState||(a.onreadystatechange=null,t())}:a.onload=function(){t()},a.src=e,document.getElementsByTagName("body")[0].appendChild(a)}</script><script type="module" src="/js/main.js"></script><script>$(document).ready((function(){$("del").attr("title","你知道的太多了ヾ(▼ﾍ▼；) (#｀皿´メ)"),$(".toc-card").width($("#right-col").width()),$("a.footnote-ref").each((function(t,e){let i=$(this).parents("article").attr("id"),o=$(this).attr("href");e.setAttribute("data-toggle","tooltip"),e.setAttribute("data-html","true"),e.setAttribute("title",$("#"+i+" "+o).html())})),setInterval(()=>{$("#site-bg").fadeTo(1e3,.1,()=>{$("#site-bg").css("background-image",'url("/img/site-bg/bg-'+Math.floor(8*Math.random())+'.jpg")')}),$("#site-bg").fadeTo(2e3,.2)},3e4),siteBgElem=document.getElementById("site-bg"),siteBgElem&&siteBgElem.clientWidth>0&&siteBgElem.clientHeight>0&&loadScript("/js/widget/canvas-nest.js",()=>{new CanvasNest(siteBgElem,{opacity:1,pointColor:"255,255,0",color:"255,255,0",count:30})})})),$(window).on("load",(function(){$("#sidebar-sticky--bottom").height($("#right-col").height()-$("#sidebar").height()-$("#footer").height())})),$((function(){$("[data-toggle='tooltip']").tooltip()}))</script></body></html>